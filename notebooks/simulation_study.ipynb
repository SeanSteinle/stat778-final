{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "latter-beverage",
   "metadata": {},
   "source": [
    "# STAT778: Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demographic-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import uniform, normal, multivariate_normal, exponential, gamma\n",
    "import scipy as sc\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spare-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it's not quite this. 3.2 does some sort of learning. how?\n",
    "#we're measuring the likelihood (via the pdf) of x given our parameters and the result.\n",
    "#THEN we combine that with our prior.\n",
    "#Then we have a posterior belief about how possible these parameters are given the data we just saw and our prior belief.\n",
    "#now we binarize this belief stochastically! and move onto the next iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-egyptian",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings with a Bayesian Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "binary-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metropolis-hastings functions\n",
    "def sample(data: np.ndarray, N: int, B: int, start_theta: tuple, search_breadth: float=0.5):\n",
    "    \"\"\"Takes N samples via the Metropolis-Hastings algorithm, with B burn-in samples.\"\"\"\n",
    "    theta = start_theta\n",
    "    for b in range(B): #burnin samples\n",
    "        results = step(data, theta, search_breadth)\n",
    "        theta = results['theta']\n",
    "    \n",
    "    samples = []\n",
    "    for n in range(N): #real samples\n",
    "        results = step(data, theta, search_breadth)\n",
    "        theta = results['theta']\n",
    "        samples.append(results)\n",
    "    return samples\n",
    "\n",
    "def step(data: np.ndarray, theta: tuple, search_breadth: float):\n",
    "    \"\"\"Takes one step in the Metropolis-Hastings algorithm by generating a new theta and comparing to a given theta.\"\"\"\n",
    "    theta_prime = sample_theta(theta, search_breadth) #sample a new set of parameters\n",
    "    acceptance_log_prob = min(1,calc_acceptance_prob(theta, theta_prime, data, search_breadth)) #calculate the probability of acceptance\n",
    "    accepted = np.exp(acceptance_log_prob) >= uniform() #probabilistically determine acceptance \n",
    "    return {'accepted': accepted, 'acceptance_prob': np.exp(acceptance_log_prob), 'theta': theta_prime if accepted else theta} #return results, update theta if samples accepted\n",
    "\n",
    "def sample_theta(theta: tuple, search_breadth: float):\n",
    "    \"\"\"Samples theta parameters--slope, intercept, and standard deviation.\"\"\"\n",
    "    a,b,sigma = theta\n",
    "    a,b = multivariate_normal([a,b], [[search_breadth**2,0],[0,search_breadth**2]])\n",
    "    sigma = gamma(sigma*search_breadth*500, 1/(search_breadth*500))\n",
    "    theta = a,b,sigma\n",
    "    return theta\n",
    "\n",
    "def calc_acceptance_prob(theta: tuple, theta_prime: tuple, data: np.ndarray, search_breadth: float):\n",
    "    \"\"\"Calculates acceptance probability by using a Bayesian linear model.\"\"\"\n",
    "    theta_likelihood = likelihood(theta, data)\n",
    "    theta_prior = prior(theta)\n",
    "    \n",
    "    theta_p_likelihood = likelihood(theta_prime, data)\n",
    "    theta_p_prior = prior(theta_prime)\n",
    "    \n",
    "    pr = proposal_ratio(theta, theta_prime, search_breadth)\n",
    "    acceptance_ratio = theta_p_likelihood - theta_likelihood + theta_p_prior - theta_prior + pr\n",
    "    return acceptance_ratio\n",
    "\n",
    "#bayesian functions\n",
    "def likelihood(theta: tuple, data: np.ndarray):\n",
    "    \"\"\"Calculates the likelihood component of our linear model by measuring our parameters theta on the given data.\"\"\"\n",
    "    a,b,sigma = theta\n",
    "    x,y = data[0],data[1]\n",
    "    likelihoods = sc.stats.norm.logpdf(y, loc=a*x+b, scale=sigma) #find the likelihood of a sample given a normal distribution specified by our parameters and the data\n",
    "    return np.sum(likelihoods) #use log likelihood for stability\n",
    "\n",
    "def prior(theta: tuple):\n",
    "    \"\"\"Calculates the prior component of our linear model, specified \"\"\"\n",
    "    a,b,sigma = theta\n",
    "    ab_prior = sc.stats.multivariate_normal.logpdf([a,b], [0,0], [[100,0],[0,100]]) #cov defaults to 1\n",
    "    sigma_prob = sc.stats.gamma.logpdf(sigma, 1, 1)\n",
    "    return np.sum([ab_prior,sigma_prob])\n",
    "\n",
    "def proposal_ratio(theta: tuple, theta_prime: tuple, search_breadth: float):\n",
    "    \"\"\"Offsets bidirectionality of chained samples.\"\"\"\n",
    "    a,b,sigma = theta\n",
    "    a_p,b_p,sigma_p = theta_prime\n",
    "    old_given_new_ab = sc.stats.multivariate_normal.logpdf([a,b],[a_p,b_p],[[search_breadth**2,0],[0,search_breadth**2]])\n",
    "    old_given_new_sigma = sc.stats.gamma.logpdf(sigma, sigma_p*search_breadth*500, scale=1/(500*search_breadth))\n",
    "    old_given_new = old_given_new_ab + old_given_new_sigma\n",
    "    \n",
    "    new_given_old_ab = sc.stats.multivariate_normal.logpdf([a_p,b_p],[a,b],[[search_breadth**2,0],[0,search_breadth**2]])\n",
    "    new_given_old_sigma = sc.stats.gamma.logpdf(sigma_p, sigma*search_breadth*500, scale=1/(500*search_breadth))\n",
    "    new_given_old = new_given_old_ab - new_given_old_sigma\n",
    "\n",
    "    return old_given_new - new_given_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "electronic-rapid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accepted': True,\n",
       " 'acceptance_prob': 2.718281828459045,\n",
       " 'theta': (4.326904920933997, 0.6682358378920995, 2.0718688171599235)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.rand(10000)\n",
    "Y = np.random.normal(4,2,10000)\n",
    "data = np.vstack((X,Y))\n",
    "step(data,(4,0,2),0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-flashing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling with breadth 0.13\n"
     ]
    }
   ],
   "source": [
    "#if we start on the correct parameters (so theoretically no burn-in) how does our acceptance rate vary with breadth value?\n",
    "X = np.random.rand(1000000)\n",
    "Y = np.random.normal(4,2,1000000)\n",
    "data = np.vstack((X,Y))\n",
    "rates = {'breadth_value':[],'acceptance_rate':[]}\n",
    "for breadth in [0.13,0.11,0.09,0.07,0.05]:\n",
    "    print(f\"sampling with breadth {breadth}\")\n",
    "    samples = sample(data, 10000, 0, (0,4,2), breadth)\n",
    "    df = pd.DataFrame(samples)\n",
    "    rates['breadth_value'].append(breadth)\n",
    "    rates['acceptance_rate'].append(df['accepted'].sum()/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sonic-mississippi",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-6-6aaf1f276005>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-6aaf1f276005>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-obligation",
   "metadata": {},
   "source": [
    "## Zero Case: N(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(10000)\n",
    "Y = np.random.normal(0,1,10000)\n",
    "data = np.vstack((X,Y))\n",
    "samples = sample(data, 30000, 0, (0,0,1), 1)\n",
    "df = pd.DataFrame(samples)\n",
    "df[['a','b','sigma']] = pd.DataFrame(df['theta'].tolist(), index=df.index)\n",
    "df = df.drop(['theta'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,Y)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"The Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(df)),df['a'], label='slope')\n",
    "plt.plot(range(len(df)),df['b'], label='intercept')\n",
    "plt.plot(range(len(df)),df['sigma'], label='variance')\n",
    "plt.plot(range(len(df)),df['acceptance_prob'], label='accept_prob')\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(df)),df['acceptance_prob'], label='accept_prob')\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-bookmark",
   "metadata": {},
   "source": [
    "## Nonzero Case: N(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(10000)\n",
    "Y = np.random.normal(-13,8,10000)\n",
    "data = np.vstack((X,Y))\n",
    "samples = sample(data, 20000, 0, (0,4,2), 0.2)\n",
    "df = pd.DataFrame(samples)\n",
    "df[['a','b','sigma']] = pd.DataFrame(df['theta'].tolist(), index=df.index)\n",
    "df = df.drop(['theta'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,Y)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"The Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "#it accepts every single one?\n",
    "#does it arrive to the right parameters?\n",
    "#effect of changing starting point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(df)),df['a'], label='slope')\n",
    "plt.plot(range(len(df)),df['b'], label='intercept')\n",
    "plt.plot(range(len(df)),df['sigma'], label='variance')\n",
    "#plt.plot(range(len(df)),df['acceptance_prob'], label='accept_prob')\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(df)),df['acceptance_prob'], label='accept_prob')\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['acceptance_prob'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-tonight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['accepted'].sum()/len(df))\n",
    "#about 1.5% accepted with a 0.5 breadth rate\n",
    "#about 2.5% accepted with a 0.2 breadth rate\n",
    "#about 1% accepted with 0.01 breadth rate\n",
    "#about 0.015% accepted with a 0.001 breadth rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-liberty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['accepted']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-share",
   "metadata": {},
   "source": [
    "## The Larger Case: N(50, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(100)\n",
    "Y = np.random.normal(4,2,10000)\n",
    "data = np.vstack((X,Y))\n",
    "samples = sample(data, 30000, 0, (0,0,1), 1)\n",
    "df = pd.DataFrame(samples)\n",
    "df[['a','b','sigma']] = pd.DataFrame(df['theta'].tolist(), index=df.index)\n",
    "df = df.drop(['theta'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(df)),df['a'], label='slope')\n",
    "plt.plot(range(len(df)),df['b'], label='intercept')\n",
    "plt.plot(range(len(df)),df['sigma'], label='variance')\n",
    "plt.plot(range(len(df)),df['acceptance_prob'], label='accept_prob')\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(df)),df['acceptance_prob'], label='accept_prob')\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
